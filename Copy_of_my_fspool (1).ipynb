{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of my_fspool.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9bef20ffbbb74b4a87a7da3405e5f0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1b6c86c95f554363be596fd77fcaff30",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51a953ae7dd74b489bd89ac07136ffc4",
              "IPY_MODEL_6d28f910daae45f496245637d5dd1bee"
            ]
          }
        },
        "1b6c86c95f554363be596fd77fcaff30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51a953ae7dd74b489bd89ac07136ffc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4fede376e83e461b97e8375a852fa3d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 34,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0adace5a08044d78448bfb8b1af73d8"
          }
        },
        "6d28f910daae45f496245637d5dd1bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2cbab098007a4b48b1b611aaa2ad757c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 68% 34/50 [05:36&lt;02:29,  9.37s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bc0a6fd7a0546eea7aa50c36ecaee81"
          }
        },
        "4fede376e83e461b97e8375a852fa3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0adace5a08044d78448bfb8b1af73d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cbab098007a4b48b1b611aaa2ad757c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bc0a6fd7a0546eea7aa50c36ecaee81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iDta3MELGkZ",
        "colab_type": "code",
        "outputId": "480fbba6-69de-45f0-8211-0b8d9a84f797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpSiOszm6GvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5aaf82b-d1df-4268-8562-083387547ee5"
      },
      "source": [
        "!pip install -q --upgrade ipython==5.5.0\n",
        "!pip install -q --upgrade ipykernel==4.6.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▏                            | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 3.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP6svWshN9vn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45782c07-e39f-4456-d05f-37ee6ab47610"
      },
      "source": [
        "cd /content/drive/My\\ Drive/textual_analysis_email/fspool/autoencoder"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/textual_analysis_email/fspool/autoencoder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NN4GVMGdYQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cd /content/drive/My\\ Drive/projects/textual_analysis_email/fspool/autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DQB_1vn9gVm",
        "colab_type": "code",
        "outputId": "7e621ab0-fa7d-4290-a19f-086b6f1d7b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!pip install cardinality"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cardinality\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/cb/8cf5275de65703cdd11365ed6ab71bd607905f4e6e530596fe399246fdc1/cardinality-0.1.1.tar.gz\n",
            "Building wheels for collected packages: cardinality\n",
            "  Building wheel for cardinality (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cardinality: filename=cardinality-0.1.1-cp36-none-any.whl size=2604 sha256=d22e00884c424cb868ec972ce52ca714f2b4c4ae398fe54e0e6964f4c6c3541e\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/e6/49/f402e4a90cc81761199d852dfdc3195169af13e2e09608f053\n",
            "Successfully built cardinality\n",
            "Installing collected packages: cardinality\n",
            "Successfully installed cardinality-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhwvhoX4uEmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.multiprocessing as mp\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import scipy.optimize\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from model import *\n",
        "from data_reader import load_bipartite_hypergraph,pad_zeros\n",
        "from data_processor import data_process\n",
        "from node2vec import *\n",
        "import data\n",
        "import track\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2GYpke-Ab0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7be730ad-e1ac-43ed-f04a-95ae715a3788"
      },
      "source": [
        "cd /content/drive/My\\ Drive/textual_analysis_email"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/textual_analysis_email\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njExsICWedqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cd /content/drive/My\\ Drive/projects/textual_analysis_email"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OFyQXDhlm0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1105ec1a-891b-4cd9-dfdc-d3cf7c266d2f"
      },
      "source": [
        "cd /content/drive/My\\ Drive/textual_analysis_email/s2slp"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/textual_analysis_email/s2slp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GUGIwrTek7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cd /content/drive/My\\ Drive/projects/textual_analysis_email/s2slp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbbpsYsNAPsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# home_path = '/content/drive/My Drive/projects/textual_analysis_email/'\n",
        "\n",
        "home_path = '/content/drive/My Drive/textual_analysis_email/'\n",
        "\n",
        "# sample_path = os.path.join(home_path, 'sample_data')\n",
        "\n",
        "data_params = {'home_path': home_path,\n",
        "               'r_label_file': 'id_p_map.txt',\n",
        "               'u_label_file': 'id_a_map.txt',\n",
        "               'v_label_file': 'id_k_map.txt',\n",
        "               'r_u_list_file': 'p_a_list_train.txt',\n",
        "               'r_v_list_file': 'p_k_list_train.txt',\n",
        "               'emb_pkl_file': 'nodevectors.pkl'}\n",
        "# methods = [commonneigh, admic_adar, jaccard]\n",
        "# method_name_map = dict(zip(methods, ['CN', 'AA', 'JC']))\n",
        "num_iter = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ZS0TVzBgjS",
        "colab_type": "code",
        "outputId": "7cb36647-9070-4815-d748-77fb738353ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "pos_A, pos_B = load_bipartite_hypergraph(data_params)\n",
        "G, obs_pos, unobs_data, V_offset = data_process(pos_A, pos_B, neg_pos_ratio = 1, unobs_ratio=0.9)\n",
        "\n",
        "max_id=max(list(G.nodes))\n",
        "max_id\n",
        "\n",
        "\n",
        "embedding_map=model(G)\n",
        "\n",
        "emb_map=[]\n",
        "\n",
        "for i in range(0,max_id):\n",
        "  emb_map.append(embedding_map.get_vector(str(i)))\n",
        "\n",
        "emb_map.append(np.zeros(128,dtype='float'))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Walk iteration:\n",
            "1 / 10\n",
            "2 / 10\n",
            "3 / 10\n",
            "4 / 10\n",
            "5 / 10\n",
            "6 / 10\n",
            "7 / 10\n",
            "8 / 10\n",
            "9 / 10\n",
            "10 / 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StSs8QyWYu2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapping(data,max_id):\n",
        "\n",
        "\n",
        "    pairs, labels = zip(*data)\n",
        "    U, V = zip(*pairs)\n",
        "\n",
        "    n_points_U = np.array([len(x) for x in U])\n",
        "    n_points_V = np.array([len(x) for x in V])\n",
        "    cardinality_U = max(n_points_U)\n",
        "    cardinality_V = max(n_points_V)\n",
        "\n",
        "\n",
        "    U = [x + [max_id]*(cardinality_U - len(x)) for x in U]\n",
        "    V = [x + [max_id]*(cardinality_V - len(x)) for x in V]\n",
        "    return U, V, n_points_U, n_points_V, cardinality_U, cardinality_V, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG678jSQ1gFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(train_data),len(test_data),len(unobs_data)\n",
        "# import pandas as pd\n",
        "# pd.DataFrame(train_data, columns = ['pair', 'label'])\n",
        "# pd.DataFrame(test_data, columns = ['pair', 'label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2z6aQNlBj3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FSEncoder(nn.Module):\n",
        "    def __init__(self, *, input_channels, output_channels, dim, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(input_channels, dim, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(dim, dim, 1),\n",
        "        )\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(dim, dim, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim, output_channels, 1),\n",
        "        )\n",
        "        self.pool = FSPool(dim, 20, relaxed=kwargs.get('relaxed', True))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, n_points, *args):\n",
        "        x = self.conv(x)\n",
        "        x, perm = self.pool(x, n_points)\n",
        "\n",
        "        x = self.lin(x)\n",
        "        return x, perm\n",
        "\n",
        "class BLP(nn.Module):\n",
        "    def __init__(self, *, input_channels, output_channels, dim, **kwargs):\n",
        "        super().__init__()\n",
        "        self.enc_U = FSEncoder(input_channels = input_channels,\n",
        "                                output_channels = output_channels,\n",
        "                                set_size = kwargs['set_size_U'],\n",
        "                               dim = dim,\n",
        "                                **kwargs)\n",
        "        self.enc_V = FSEncoder(input_channels = input_channels,\n",
        "                                output_channels = output_channels,\n",
        "                                set_size = kwargs['set_size_V'],\n",
        "                               dim = dim,\n",
        "                                **kwargs)\n",
        "        self.classifier = nn.Linear(2*output_channels, 1)\n",
        "    def forward(self, sample, *args):\n",
        "        U, V, n_points_U, n_points_V = sample\n",
        "        x_U, _ = self.enc_U(U, n_points_U)\n",
        "        x_V, _ = self.enc_V(V, n_points_V)\n",
        "        x = self.classifier(torch.cat([x_U, x_V], dim=1))\n",
        "        return x\n",
        "\n",
        "class EMB_LAYER(nn.Module):\n",
        "    def __init__(self,word_map,padd,input_channels, output_channels, dim, set_size_U,set_size_V,**kwargs):\n",
        "        super().__init__()\n",
        "        kwargs['set_size_U'] = set_size_U\n",
        "        kwargs['set_size_V'] = set_size_V\n",
        "        \n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings=word_map,freeze=False,padding_idx=padd)\n",
        "\n",
        "        self.out_ = BLP(input_channels = input_channels,\n",
        "                                output_channels = output_channels,\n",
        "                               dim = dim,\n",
        "                                **kwargs)\n",
        "        self.c_U=set_size_U\n",
        "        self.c_V=set_size_V\n",
        "        self.padd=padd\n",
        "\n",
        "    def forward(self, sample, *args):\n",
        "        U, V, n_points_U, n_points_V,mask_U,mask_V = sample\n",
        "        U_=self.embedding(U)\n",
        "        V_=self.embedding(V)\n",
        "\n",
        "        #print(U_.size())\n",
        "        \n",
        "        \"\"\"mask needed\"\"\"\n",
        "\n",
        "        \n",
        "\n",
        "        U_=torch.cat([U_,mask_U],dim=2)\n",
        "        \n",
        "        V_=torch.cat([V_,mask_V],dim=2)\n",
        "\n",
        "\n",
        "\n",
        "        sample=(torch.transpose(U_,1,2),torch.transpose(V_,1,2),n_points_U,n_points_V)\n",
        "        x=self.out_(sample)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZerfpJjEn2Q6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "b8464353-ce71-41a2-bdaf-124b69ea04de"
      },
      "source": [
        "weight=torch.from_numpy(np.matrix(emb_map)).type(torch.FloatTensor)\n",
        "\n",
        "\n",
        "weight=torch.randn((weight.size(0),weight.size(1))).type(torch.FloatTensor)\n",
        "weight[weight.size(0)-1][:]=0\n",
        "weight[weight.size(0)-1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NioMyqbmv9Xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "hidden_dim = 128\n",
        "latent_dim = 32\n",
        "\n",
        "\n",
        "U, V, n_points_U, n_points_V, cardinality_U, cardinality_V, labels = mapping(unobs_data, max_id)\n",
        "unobs_data=list(zip(U, V, n_points_U, n_points_V, labels))\n",
        "train_data,test_data=train_test_split(unobs_data,test_size=0.2)\n",
        "U, V, n_points_U, n_points_V, labels=zip(*train_data)\n",
        "\n",
        "U=torch.from_numpy(np.array(U))\n",
        "V=torch.from_numpy(np.array(V))\n",
        "\n",
        "\n",
        "\n",
        "tU, tV, tn_points_U, tn_points_V, tlabels=zip(*test_data)\n",
        "tU=torch.from_numpy(np.array(tU))\n",
        "tV=torch.from_numpy(np.array(tV))\n",
        "\n",
        "\n",
        "\n",
        "# tpoints_U, tpoints_V, tn_U, tn_V, tc_U, tc_V, t_labels = mapping(embedding_map,test_data)\n",
        "\n",
        "# points_U = pad_zeros(torch.Tensor(points_U), max([c_U,tc_U]))\n",
        "# points_V = pad_zeros(torch.Tensor(points_V), max([c_V,tc_V]))\n",
        "\n",
        "# tpoints_U = pad_zeros(torch.Tensor(tpoints_U), max([c_U,tc_U]))\n",
        "# tpoints_V = pad_zeros(torch.Tensor(tpoints_V), max([c_V,tc_V]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-NWgD0edTTn",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBOHZPJMMsIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "U.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyIku0cMNgU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# net = BLP(input_channels = 129,\n",
        "#           output_channels = latent_dim,\n",
        "#           set_size_U = cardinality_U,\n",
        "#           set_size_V = cardinality_V,\n",
        "#           dim = hidden_dim,\n",
        "#           skip = False,\n",
        "#           relaxed = False)\n",
        "\n",
        "\n",
        "net=EMB_LAYER(weight,max_id,129,\n",
        "              latent_dim,hidden_dim,\n",
        "              set_size_U=int(cardinality_U),\n",
        "              set_size_V = int(cardinality_V),\n",
        "              skip=False,relaxed=False)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=1E-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nTOJ5Aq-s3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# net.load_state_dict(torch.load('fs_pool_authors_keywords.model'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeyEh2FREUlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_U = torch.from_numpy(np.array([[1]*n_points_U[i] + [0]*(cardinality_U-n_points_U[i]) for i in range(len(U))])).type(torch.FloatTensor).view(U.shape[0],cardinality_U,1)\n",
        "mask_V= torch.from_numpy(np.array([[1]*n_points_V[i] + [0]*(cardinality_V-n_points_V[i]) for i in range(len(V))])).type(torch.FloatTensor).view(V.shape[0],cardinality_V,1)\n",
        "tmask_U = torch.from_numpy(np.array([[1]*tn_points_U[i] + [0]*(cardinality_U-tn_points_U[i]) for i in range(len(tU))])).type(torch.FloatTensor).view(tU.shape[0],cardinality_U,1)\n",
        "tmask_V= torch.from_numpy(np.array([[1]*tn_points_V[i] + [0]*(cardinality_V-tn_points_V[i]) for i in range(len(tV))])).type(torch.FloatTensor).view(tV.shape[0],cardinality_V,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgGtSButFU9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "import pickle\n",
        "losses = []\n",
        "test_losses = []\n",
        "gold = torch.Tensor(labels).view(-1, 1)\n",
        "tgold = torch.Tensor(tlabels).view(-1, 1)\n",
        "\n",
        "n_epoch = 50\n",
        "inputs = (U,V,  torch.from_numpy(np.array((list(map(int,n_points_U))))), torch.from_numpy(np.array(list(map(int,n_points_V)))),mask_U,mask_V)\n",
        "t_input =(tU, tV, torch.from_numpy(np.array(list(map(int,tn_points_U)))), torch.from_numpy(np.array(list(map(int, tn_points_V)))),tmask_U,tmask_V)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNrTmxYiFqdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(cardinality_U)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLIx3JqkFW9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# net=model_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpyEJSQAWbJm",
        "colab_type": "code",
        "outputId": "693d8f66-4d03-4b2e-dd95-5cfee6cc945c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "9bef20ffbbb74b4a87a7da3405e5f0e6",
            "1b6c86c95f554363be596fd77fcaff30",
            "51a953ae7dd74b489bd89ac07136ffc4",
            "6d28f910daae45f496245637d5dd1bee",
            "4fede376e83e461b97e8375a852fa3d0",
            "b0adace5a08044d78448bfb8b1af73d8",
            "2cbab098007a4b48b1b611aaa2ad757c",
            "9bc0a6fd7a0546eea7aa50c36ecaee81"
          ]
        }
      },
      "source": [
        "\n",
        "aucs=[]\n",
        "\n",
        "for _ in tqdm_notebook(range(n_epoch)):\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    out = net(inputs)\n",
        "\n",
        "    torch.save(net.state_dict, 'fs_pool_authors_keywords.model')\n",
        "\n",
        "    loss = nn.BCEWithLogitsLoss()(out, gold)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print(\"after\",_)\n",
        "    losses.append(loss)\n",
        "    net.eval()\n",
        "    test_out = net(t_input)\n",
        "\n",
        "\n",
        "    #aucs.append((roc_auc_score(gold,out),roc_auc_score(tgold,test_out)))\n",
        "\n",
        "\n",
        "    test_loss = nn.BCEWithLogitsLoss()(test_out, tgold)\n",
        "    # print(\"before\",_)\n",
        "    test_losses.append(test_loss)\n",
        "    \n",
        "    pickle.dump({'train_losses': losses, 'test_losses': test_losses}, open('fs_pool_authors_keywords.losses.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bef20ffbbb74b4a87a7da3405e5f0e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type EMB_LAYER. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BLP. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FSEncoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv1d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FSPool. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtCAJY9aZRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roc_auc_score(gold.cpu().detach().numpy(),nn.Sigmoid()(out).cpu().detach().numpy()),roc_auc_score(tgold.cpu().detach().numpy(),nn.Sigmoid()(test_out).cpu().detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJdPVpmgWwAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "loss_dict = pickle.load(open('fs_pool_authors_keywords.losses.pkl', 'rb'))\n",
        "model_dict = pickle.load(open('fs_pool_authors_keywords.model', 'rb'))\n",
        "\n",
        "losses = loss_dict['train_losses']\n",
        "test_losses = loss_dict['test_losses']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePnSSC8yZJAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDeJh3rnZUTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "n_epoch1 = len(losses)\n",
        "plt.plot(range(n_epoch1), losses, label='train')\n",
        "plt.plot(range(n_epoch1), test_losses, label='test')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snmIHQS7Va2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# mse, cha, acc = torch.FloatTensor([-1, -1, -1])\n",
        "# if not args.classify:\n",
        "#     mse = (pred - points).pow(2).mean()\n",
        "#     cha = chamfer_loss(pred, points)\n",
        "#     if args.loss == 'direct':\n",
        "#         loss = mse\n",
        "#     elif args.loss == 'chamfer':\n",
        "#         loss = cha\n",
        "#     elif args.loss == 'hungarian':\n",
        "#         loss = hungarian_loss(pred, points)\n",
        "#     else:\n",
        "#         raise NotImplementedError\n",
        "# else:\n",
        "#     loss = F.cross_entropy(pred, labels)\n",
        "#     acc = (pred.max(dim=1)[1] == labels).float().mean()\n",
        "\n",
        "# if train:\n",
        "#     optimizer.zero_grad()\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "# tracked_mse = tracker.update('{}_mse'.format(prefix), mse.item())\n",
        "# tracked_cha = tracker.update('{}_cha'.format(prefix), cha.item())\n",
        "# tracked_loss = tracker.update('{}_loss'.format(prefix), loss.item())\n",
        "# tracked_acc = tracker.update('{}_acc'.format(prefix), acc.item())\n",
        "\n",
        "# fmt = '{:.5f}'.format\n",
        "# loader.set_postfix(\n",
        "#     mse=fmt(tracked_mse),\n",
        "#     cha=fmt(tracked_cha),\n",
        "#     loss=fmt(tracked_loss),\n",
        "#     acc=fmt(tracked_acc),\n",
        "# )\n",
        "\n",
        "# if args.show and not train:\n",
        "#     #scatter(input_points, n_points, marker='o', transpose=args.mnist)\n",
        "#     scatter(pred, n_points, marker='x', transpose=args.mnist)\n",
        "#     plt.axes().set_aspect('equal', 'datalim')\n",
        "#     plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etN2DKyHz3rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# points, labels, n_points = samples[0]\n",
        "# n_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRT4GOnBwYyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import subprocess\n",
        "# git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'])\n",
        "\n",
        "# torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# for epoch in range(args.epochs):\n",
        "# tracker.new_epoch()\n",
        "# with mp.Pool(4) as pool:\n",
        "#     if not args.eval_only:\n",
        "#         run(net, train_loader, optimizer, train=True, epoch=epoch, pool=pool)\n",
        "#     if not args.train_only:\n",
        "#         run(net, test_loader, optimizer, train=False, epoch=epoch, pool=pool)\n",
        "\n",
        "# results = {\n",
        "#     'name': args.name,\n",
        "#     'tracker': tracker.data,\n",
        "#     'weights': net.state_dict() if not args.multi_gpu else net.module.state_dict(),\n",
        "#     'args': vars(args),\n",
        "#     'hash': git_hash,\n",
        "# }\n",
        "# torch.save(results, os.path.join('logs', args.name))\n",
        "# if args.eval_only:\n",
        "#     break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxCdlnz0uTRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}